#!/usr/bin/env python3
"""
è®­ç»ƒMask R-CNNå’ŒSparse R-CNNæ¨¡å‹çš„è„šæœ¬ï¼ˆä¿®å¤ç‰ˆï¼‰
æ”¯æŒTensorboardå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
ä½¿ç”¨ç®€åŒ–é…ç½®æ–‡ä»¶é¿å…ç»§æ‰¿è¯­æ³•é—®é¢˜
"""

import os
import sys
import subprocess
import argparse
from pathlib import Path

def get_gpu_count():
    """è·å–å¯ç”¨GPUæ•°é‡"""
    if 'CUDA_VISIBLE_DEVICES' in os.environ:
        cuda_devices = os.environ['CUDA_VISIBLE_DEVICES']
        if cuda_devices:
            return len(cuda_devices.split(','))
        else:
            return 0
    else:
        # å¦‚æœæ²¡æœ‰è®¾ç½®CUDA_VISIBLE_DEVICESï¼Œå°è¯•æ£€æµ‹æ‰€æœ‰å¯ç”¨GPU
        try:
            result = subprocess.run(['nvidia-smi', '--list-gpus'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                return len(result.stdout.strip().split('\n'))
        except FileNotFoundError:
            pass
        return 1  # é»˜è®¤å‡è®¾æœ‰1å¼ GPU

def update_config_for_gpus(config_file, gpu_count):
    """æ ¹æ®GPUæ•°é‡æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„å­¦ä¹ ç‡"""
    print(f"æ£€æµ‹åˆ° {gpu_count} å¼ GPUï¼Œè°ƒæ•´é…ç½®...")
    
    # è¯»å–é…ç½®æ–‡ä»¶
    with open(config_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # å¤‡ä»½åŸå§‹é…ç½®
    backup_file = config_file + '.backup'
    with open(backup_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    # æ ¹æ®GPUæ•°é‡è°ƒæ•´å­¦ä¹ ç‡
    if 'sparse_rcnn' in config_file:
        # Sparse R-CNNä½¿ç”¨AdamWä¼˜åŒ–å™¨
        base_lr = 0.000025
        new_lr = base_lr * gpu_count
        # æ›´æ–°40ä¸ªepochçš„é…ç½®
        content = content.replace(
            f'lr=2.5e-05 * 4',  # åŸæ¥çš„4å¡é…ç½®
            f'lr={base_lr} * {gpu_count}'
        )
        print(f"Sparse R-CNNå­¦ä¹ ç‡è°ƒæ•´ä¸º: {new_lr} (40ä¸ªepoch)")
    else:
        # Mask R-CNNä½¿ç”¨SGDä¼˜åŒ–å™¨
        base_lr = 0.02
        new_lr = base_lr * gpu_count
        # æ›´æ–°40ä¸ªepochçš„é…ç½®
        content = content.replace(
            f'lr=0.02 * 8',  # åŸæ¥çš„8å¡é…ç½®
            f'lr={base_lr} * {gpu_count}'
        )
        print(f"Mask R-CNNå­¦ä¹ ç‡è°ƒæ•´ä¸º: {new_lr} (40ä¸ªepoch)")
    
    # å†™å›é…ç½®æ–‡ä»¶
    with open(config_file, 'w', encoding='utf-8') as f:
        f.write(content)

def run_command(cmd, check=True):
    """è¿è¡Œshellå‘½ä»¤"""
    print(f"æ‰§è¡Œå‘½ä»¤: {cmd}")
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    if check and result.returncode != 0:
        print(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.stderr}")
        print(f"æ ‡å‡†è¾“å‡º: {result.stdout}")
        return False
    print(f"å‘½ä»¤æ‰§è¡ŒæˆåŠŸ: {result.stdout}")
    return True

def train_mask_rcnn():
    """è®­ç»ƒMask R-CNNæ¨¡å‹"""
    print("å¼€å§‹è®­ç»ƒMask R-CNN...")
    
    config_file = "configs/mask_rcnn_voc_simple.py"  # ä½¿ç”¨ç®€åŒ–é…ç½®æ–‡ä»¶
    work_dir = "work_dirs/mask_rcnn"
    
    # åˆ›å»ºå·¥ä½œç›®å½•
    Path(work_dir).mkdir(parents=True, exist_ok=True)
    
    # è·å–GPUæ•°é‡å¹¶æ›´æ–°é…ç½®
    gpu_count = get_gpu_count()
    update_config_for_gpus(config_file, gpu_count)
    
    # æ ¹æ®GPUæ•°é‡é€‰æ‹©è®­ç»ƒå‘½ä»¤
    if gpu_count > 1:
        # å¤šå¡åˆ†å¸ƒå¼è®­ç»ƒ
        cmd = f"python -m torch.distributed.launch --nproc_per_node={gpu_count} mmdetection_repo/tools/train.py {config_file} --work-dir {work_dir} --launcher pytorch"
    else:
        # å•å¡è®­ç»ƒ
        cmd = f"python mmdetection_repo/tools/train.py {config_file} --work-dir {work_dir}"
    
    return run_command(cmd)

def train_sparse_rcnn():
    """è®­ç»ƒSparse R-CNNæ¨¡å‹"""
    print("å¼€å§‹è®­ç»ƒSparse R-CNN...")
    
    config_file = "sparse_rcnn_config_simple.py"  # ä½¿ç”¨ç®€åŒ–é…ç½®æ–‡ä»¶
    work_dir = "work_dirs/sparse_rcnn"
    
    # åˆ›å»ºå·¥ä½œç›®å½•
    Path(work_dir).mkdir(parents=True, exist_ok=True)
    
    # è·å–GPUæ•°é‡å¹¶æ›´æ–°é…ç½®
    gpu_count = get_gpu_count()
    update_config_for_gpus(config_file, gpu_count)
    
    # æ ¹æ®GPUæ•°é‡é€‰æ‹©è®­ç»ƒå‘½ä»¤
    if gpu_count > 1:
        # å¤šå¡åˆ†å¸ƒå¼è®­ç»ƒ
        cmd = f"python -m torch.distributed.launch --nproc_per_node={gpu_count} mmdetection_repo/tools/train.py {config_file} --work-dir {work_dir} --launcher pytorch"
    else:
        # å•å¡è®­ç»ƒ
        cmd = f"python mmdetection_repo/tools/train.py {config_file} --work-dir {work_dir}"
    
    return run_command(cmd)

def test_model(config_file, checkpoint_file, model_name):
    """ä½¿ç”¨æœ€ä½³æƒé‡åœ¨VOC2012éªŒè¯é›†ä¸Šæµ‹è¯•æ¨¡å‹"""
    print(f"ä½¿ç”¨æœ€ä½³æƒé‡æµ‹è¯•{model_name}æ¨¡å‹...")
    print(f"é…ç½®æ–‡ä»¶: {config_file}")
    print(f"æƒé‡æ–‡ä»¶: {checkpoint_file}")
    print(f"æµ‹è¯•é›†: VOC2012éªŒè¯é›† (5824å¼ å›¾ç‰‡)")
    
    result_file = f"results/{model_name}_final_results.pkl"
    
    # åˆ›å»ºç»“æœç›®å½•
    Path("results").mkdir(exist_ok=True)
    Path(f"visualizations/{model_name}").mkdir(parents=True, exist_ok=True)
    
    cmd = f"""
    python mmdetection_repo/tools/test.py {config_file} {checkpoint_file} \
        --out {result_file} \
        --eval bbox segm \
        --show-dir visualizations/{model_name} \
        --cfg-options test_evaluator.classwise=True
    """
    
    success = run_command(cmd)
    if success:
        print(f"âœ… {model_name}æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“Š ç»“æœä¿å­˜åœ¨: {result_file}")
        print(f"ğŸ–¼ï¸  å¯è§†åŒ–ç»“æœä¿å­˜åœ¨: visualizations/{model_name}/")
    
    return success

def start_tensorboard_info():
    """æ˜¾ç¤ºTensorboardå¯åŠ¨ä¿¡æ¯"""
    gpu_count = get_gpu_count()
    print("\n" + "="*60)
    print("ğŸ“Š Tensorboard å¯è§†åŒ–è¯´æ˜")
    print("="*60)
    print(f"ğŸ”§ æ£€æµ‹åˆ° {gpu_count} å¼ GPUå¡")
    if 'CUDA_VISIBLE_DEVICES' in os.environ:
        print(f"ğŸ¯ ä½¿ç”¨GPU: {os.environ['CUDA_VISIBLE_DEVICES']}")
    print()
    print("ğŸ“‹ æ•°æ®é›†é…ç½®:")
    print("  ğŸ—‚ï¸  è®­ç»ƒé›†: VOC2012 train.txt (5718å¼ å›¾ç‰‡)")
    print("  ğŸ—‚ï¸  éªŒè¯é›†: VOC2012 val.txt (5824å¼ å›¾ç‰‡)")
    print("  ğŸ“… è®­ç»ƒè½®æ¬¡: 40ä¸ªepoch")
    print("  âœ… æ¯ä¸ªepochè¿›è¡ŒéªŒè¯")
    print("  ğŸ† åŸºäºéªŒè¯mAPä¿å­˜æœ€ä½³æ¨¡å‹")
    print()
    print("ğŸ”§ é…ç½®æ–‡ä»¶ä¿®å¤:")
    print("  âœ… ä½¿ç”¨ç®€åŒ–é…ç½®æ–‡ä»¶é¿å…ç»§æ‰¿è¯­æ³•é—®é¢˜")
    print("  ğŸ“ Mask R-CNN: configs/mask_rcnn_voc_simple.py")
    print("  ğŸ“ Sparse R-CNN: sparse_rcnn_config_simple.py")
    print()
    print("è®­ç»ƒå¼€å§‹åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨Tensorboard:")
    print("  python start_tensorboard.py")
    print()
    print("æˆ–è€…æ‰‹åŠ¨å¯åŠ¨:")
    print("  tensorboard --logdir=work_dirs --port=6006")
    print()
    print("ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—®: http://localhost:6006")
    print()
    print("ğŸ¯ åˆ†ç¦»çš„å¯è§†åŒ–å†…å®¹åŒ…æ‹¬:")
    print("  ğŸ“ˆ Train_Loss/: è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§lossæ›²çº¿")
    print("  ğŸ“‰ Val_Loss/: éªŒè¯è¿‡ç¨‹ä¸­çš„å„ç§lossæ›²çº¿")
    print("  ğŸ“Š Val_mAP/: éªŒè¯é›†çš„mAPå’ŒAPæ›²çº¿")
    print("  ğŸ”§ Learning_Rate/: å­¦ä¹ ç‡å˜åŒ–æ›²çº¿")
    print("  â±ï¸  Time/: è®­ç»ƒå’ŒéªŒè¯æ—¶é—´ç»Ÿè®¡")
    print("  ğŸ–¼ï¸  Val_Metrics/: å…¶ä»–éªŒè¯æŒ‡æ ‡")
    print("="*60)

def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒå’Œæµ‹è¯•ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼ˆä¿®å¤ç‰ˆï¼‰')
    parser.add_argument('--model', choices=['mask_rcnn', 'sparse_rcnn', 'both'], 
                       default='both', help='é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹')
    parser.add_argument('--test-only', action='store_true', 
                       help='åªè¿›è¡Œæµ‹è¯•ï¼Œä¸è®­ç»ƒ')
    parser.add_argument('--start-tensorboard', action='store_true',
                       help='è®­ç»ƒå®Œæˆåè‡ªåŠ¨å¯åŠ¨Tensorboard')
    parser.add_argument('--no-interactive', action='store_true',
                       help='éäº¤äº’æ¨¡å¼ï¼Œè·³è¿‡ç”¨æˆ·è¾“å…¥ï¼ˆé€‚ç”¨äºnohupç­‰åå°è¿è¡Œï¼‰')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    dirs = ["work_dirs", "results", "visualizations"]
    for dir_name in dirs:
        Path(dir_name).mkdir(exist_ok=True)
    
    # æ˜¾ç¤ºTensorboardä¿¡æ¯
    if not args.test_only:
        start_tensorboard_info()
        if not args.no_interactive:
            input("æŒ‰Enteré”®ç»§ç»­è®­ç»ƒ...")
        else:
            print("éäº¤äº’æ¨¡å¼ï¼Œè‡ªåŠ¨å¼€å§‹è®­ç»ƒ...")
    
    if not args.test_only:
        # è®­ç»ƒæ¨¡å‹
        if args.model in ['mask_rcnn', 'both']:
            success = train_mask_rcnn()
            if not success:
                print("Mask R-CNNè®­ç»ƒå¤±è´¥")
                return
        
        if args.model in ['sparse_rcnn', 'both']:
            success = train_sparse_rcnn()
            if not success:
                print("Sparse R-CNNè®­ç»ƒå¤±è´¥")
                return
    
    # ä½¿ç”¨æœ€ä½³æƒé‡æµ‹è¯•æ¨¡å‹
    print("\nğŸ† ä½¿ç”¨æœ€ä½³æƒé‡è¿›è¡Œæœ€ç»ˆæµ‹è¯•...")
    
    if args.model in ['mask_rcnn', 'both']:
        # æŸ¥æ‰¾æœ€ä½³æƒé‡æ–‡ä»¶
        if os.path.exists("work_dirs/mask_rcnn/"):
            # æŸ¥æ‰¾bestå¼€å¤´çš„æƒé‡æ–‡ä»¶
            best_files = [f for f in os.listdir("work_dirs/mask_rcnn/") if f.startswith("best_") and f.endswith(".pth")]
            if best_files:
                mask_rcnn_checkpoint = os.path.join("work_dirs/mask_rcnn/", best_files[0])
                print(f"ğŸ¯ æ‰¾åˆ°Mask R-CNNæœ€ä½³æƒé‡: {best_files[0]}")
            elif os.path.exists("work_dirs/mask_rcnn/latest.pth"):
                mask_rcnn_checkpoint = "work_dirs/mask_rcnn/latest.pth"
                print(f"âš ï¸  æœªæ‰¾åˆ°æœ€ä½³æƒé‡ï¼Œä½¿ç”¨æœ€æ–°æƒé‡: latest.pth")
            else:
                print("âŒ Mask R-CNNæ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨")
                mask_rcnn_checkpoint = None
                
            if mask_rcnn_checkpoint:
                test_model("configs/mask_rcnn_voc_simple.py", mask_rcnn_checkpoint, "mask_rcnn")
    
    if args.model in ['sparse_rcnn', 'both']:
        # æŸ¥æ‰¾æœ€ä½³æƒé‡æ–‡ä»¶
        if os.path.exists("work_dirs/sparse_rcnn/"):
            # æŸ¥æ‰¾bestå¼€å¤´çš„æƒé‡æ–‡ä»¶
            best_files = [f for f in os.listdir("work_dirs/sparse_rcnn/") if f.startswith("best_") and f.endswith(".pth")]
            if best_files:
                sparse_rcnn_checkpoint = os.path.join("work_dirs/sparse_rcnn/", best_files[0])
                print(f"ğŸ¯ æ‰¾åˆ°Sparse R-CNNæœ€ä½³æƒé‡: {best_files[0]}")
            elif os.path.exists("work_dirs/sparse_rcnn/latest.pth"):
                sparse_rcnn_checkpoint = "work_dirs/sparse_rcnn/latest.pth"
                print(f"âš ï¸  æœªæ‰¾åˆ°æœ€ä½³æƒé‡ï¼Œä½¿ç”¨æœ€æ–°æƒé‡: latest.pth")
            else:
                print("âŒ Sparse R-CNNæ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨")
                sparse_rcnn_checkpoint = None
                
            if sparse_rcnn_checkpoint:
                test_model("sparse_rcnn_config_simple.py", sparse_rcnn_checkpoint, "sparse_rcnn")
    
    print("è®­ç»ƒå’Œæµ‹è¯•å®Œæˆ!")
    
    # å¯é€‰æ‹©è‡ªåŠ¨å¯åŠ¨Tensorboard
    if args.start_tensorboard:
        print("\nå¯åŠ¨Tensorboard...")
        subprocess.run([sys.executable, "start_tensorboard.py"], cwd=".")

if __name__ == "__main__":
    main() 