#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†final_annotation_generator.pyç”Ÿæˆçš„æ ‡æ³¨è½¬æ¢ä¸ºMMDetection COCOæ ¼å¼
"""

import os
import json
import pickle
import numpy as np
import cv2
from datetime import datetime
from pathlib import Path
import pycocotools.mask as mask_util


class AnnotationToCOCOConverter:
    """å°†pickleæ ¼å¼çš„æ ‡æ³¨è½¬æ¢ä¸ºCOCOæ ¼å¼"""
    
    def __init__(self, 
                 annotation_dir="./mask_rcnn_in_tf2_keras/final_annotations",
                 output_dir="./data/coco_format",
                 voc_data_path="/mnt/data/liyu/mm/data/VOCdevkit/VOC2012"):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨
        
        Args:
            annotation_dir: pickleæ ‡æ³¨æ–‡ä»¶ç›®å½•
            output_dir: COCOæ ¼å¼è¾“å‡ºç›®å½•
            voc_data_path: VOCåŸå§‹æ•°æ®è·¯å¾„
        """
        self.annotation_dir = annotation_dir
        self.output_dir = output_dir
        self.voc_data_path = voc_data_path
        
        # VOCç±»åˆ«ï¼ˆåŒ…å«èƒŒæ™¯ç±»ï¼‰
        self.classes = [
            '_background_', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',
            'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',
            'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
        ]
        
        # COCOç±»åˆ«ï¼ˆä¸åŒ…å«èƒŒæ™¯ç±»ï¼‰
        self.coco_categories = []
        for i, class_name in enumerate(self.classes[1:], 1):  # è·³è¿‡èƒŒæ™¯ç±»
            self.coco_categories.append({
                "id": i,
                "name": class_name,
                "supercategory": "object"
            })
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        Path(os.path.join(self.output_dir, "annotations")).mkdir(exist_ok=True)
        Path(os.path.join(self.output_dir, "images")).mkdir(exist_ok=True)
        
        print(f"æ ‡æ³¨è½¬æ¢å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"  è¾“å…¥ç›®å½•: {annotation_dir}")
        print(f"  è¾“å‡ºç›®å½•: {output_dir}")
        print(f"  VOCæ•°æ®è·¯å¾„: {voc_data_path}")
        print(f"  ç±»åˆ«æ•°é‡: {len(self.coco_categories)}")
    
    def _load_pickle_data(self, split):
        """åŠ è½½pickleæ ¼å¼çš„æ ‡æ³¨æ•°æ®"""
        pickle_file = os.path.join(self.annotation_dir, f"annotations_{split}.pkl")
        
        if not os.path.exists(pickle_file):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ ‡æ³¨æ–‡ä»¶: {pickle_file}")
        
        print(f"åŠ è½½ {split} æ•°æ®: {pickle_file}")
        with open(pickle_file, 'rb') as f:
            data = pickle.load(f)
        
        return data
    
    def _get_original_image_info(self, file_name):
        """è·å–åŸå§‹å›¾åƒä¿¡æ¯"""
        # ä»æ–‡ä»¶åä¸­æå–å›¾åƒID
        image_id = os.path.splitext(file_name)[0]
        
        # æ„å»ºåŸå§‹å›¾åƒè·¯å¾„
        original_image_path = os.path.join(self.voc_data_path, "JPEGImages", file_name)
        
        # å¯¹äºä½¿ç”¨mini maskçš„æ•°æ®ï¼Œæ‰€æœ‰æ ‡æ³¨éƒ½æ˜¯åŸºäº320x320çš„å¤„ç†åå°ºå¯¸
        # å› æ­¤å›¾åƒä¿¡æ¯ä¹Ÿåº”è¯¥ä½¿ç”¨320x320ï¼Œä¸è°ƒæ•´åçš„å›¾åƒæ–‡ä»¶ä¿æŒä¸€è‡´
        return {
            "id": hash(image_id) % (2**31),  # ç”Ÿæˆå”¯ä¸€ID
            "file_name": file_name,
            "width": 320,   # ä½¿ç”¨å¤„ç†åçš„å›ºå®šå°ºå¯¸
            "height": 320,  # ä½¿ç”¨å¤„ç†åçš„å›ºå®šå°ºå¯¸
            "original_path": original_image_path
        }
    
    def _decode_mini_mask(self, mini_mask, bbox, original_size=(320, 320)):
        """å°†mini maskè§£ç ä¸ºå…¨å°ºå¯¸mask"""
        ymin, xmin, ymax, xmax = bbox.astype(int)
        
        # ç¡®ä¿è¾¹ç•Œæ¡†æœ‰æ•ˆ
        ymin = max(0, ymin)
        xmin = max(0, xmin)
        ymax = min(original_size[0], ymax)
        xmax = min(original_size[1], xmax)
        
        if ymax <= ymin or xmax <= xmin:
            return np.zeros(original_size, dtype=np.uint8)
        
        # è°ƒæ•´mini maskåˆ°è¾¹ç•Œæ¡†å°ºå¯¸
        roi_height = ymax - ymin
        roi_width = xmax - xmin
        
        if mini_mask.size > 0:
            mask_resized = cv2.resize(mini_mask.astype(np.float32), 
                                    (roi_width, roi_height), 
                                    interpolation=cv2.INTER_LINEAR)
            mask_resized = (mask_resized >= 0.5).astype(np.uint8)
        else:
            mask_resized = np.zeros((roi_height, roi_width), dtype=np.uint8)
        
        # åˆ›å»ºå…¨å°ºå¯¸mask
        full_mask = np.zeros(original_size, dtype=np.uint8)
        full_mask[ymin:ymax, xmin:xmax] = mask_resized
        
        return full_mask
    
    def _mask_to_rle(self, mask):
        """å°†maskè½¬æ¢ä¸ºRLEæ ¼å¼"""
        # ç¡®ä¿maskæ˜¯äºŒå€¼çš„
        binary_mask = (mask > 0).astype(np.uint8)
        
        # è½¬æ¢ä¸ºFortrané¡ºåºï¼ˆåˆ—ä¼˜å…ˆï¼‰
        binary_mask = np.asfortranarray(binary_mask)
        
        # ç¼–ç ä¸ºRLE
        rle = mask_util.encode(binary_mask)
        
        # ç¡®ä¿countsæ˜¯å­—ç¬¦ä¸²æ ¼å¼
        if isinstance(rle['counts'], bytes):
            rle['counts'] = rle['counts'].decode('utf-8')
        
        return rle
    
    def _copy_images_to_output(self, file_names, split):
        """å¤åˆ¶å¹¶è°ƒæ•´å›¾åƒåˆ°è¾“å‡ºç›®å½•"""
        print(f"å¤åˆ¶å¹¶è°ƒæ•´ {split} å›¾åƒåˆ°è¾“å‡ºç›®å½•...")
        
        copied_count = 0
        for file_name in file_names:
            src_path = os.path.join(self.voc_data_path, "JPEGImages", file_name)
            dst_path = os.path.join(self.output_dir, "images", file_name)
            
            if os.path.exists(src_path) and not os.path.exists(dst_path):
                try:
                    # è¯»å–åŸå§‹å›¾åƒ
                    image = cv2.imread(src_path)
                    if image is None:
                        print(f"  è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {file_name}")
                        continue
                    
                    # è°ƒæ•´å›¾åƒå°ºå¯¸ä¸º320x320ï¼ˆä¸ä¿æŒæ¯”ä¾‹ï¼Œä¸æ ‡æ³¨æ•°æ®ä¸€è‡´ï¼‰
                    resized_image = cv2.resize(image, (320, 320), interpolation=cv2.INTER_LINEAR)
                    
                    # ä¿å­˜è°ƒæ•´åçš„å›¾åƒ
                    cv2.imwrite(dst_path, resized_image)
                    copied_count += 1
                    
                except Exception as e:
                    print(f"  è­¦å‘Š: å¤„ç†å›¾åƒå¤±è´¥ {file_name}: {e}")
        
        print(f"  æˆåŠŸå¤„ç† {copied_count} å¼ å›¾åƒï¼ˆè°ƒæ•´ä¸º320x320ï¼‰")
    
    def convert_split(self, split):
        """è½¬æ¢æŒ‡å®šåˆ†å‰²çš„æ•°æ®"""
        print(f"\nå¼€å§‹è½¬æ¢ {split} æ•°æ®...")
        
        # åŠ è½½pickleæ•°æ®
        data = self._load_pickle_data(split)
        
        # æå–æ•°æ®
        batch_images = data['images']
        batch_masks = data['masks']
        batch_gt_boxes = data['gt_boxes']
        batch_labels = data['labels']
        file_names = data['file_names']
        statistics = data['statistics']
        
        print(f"æ•°æ®ç»Ÿè®¡:")
        print(f"  æ‰¹æ¬¡æ•°é‡: {len(batch_images)}")
        print(f"  å›¾åƒæ•°é‡: {len(file_names)}")
        print(f"  æ‰¹æ¬¡å¤§å°: {statistics['batch_size']}")
        print(f"  å›¾åƒå°ºå¯¸: {statistics['image_size']}")
        print(f"  ä½¿ç”¨mini mask: {statistics['use_mini_mask']}")
        
        # åˆå§‹åŒ–COCOæ ¼å¼æ•°æ®
        coco_data = {
            "info": {
                "description": f"VOC2012 {split} dataset converted from pickle format",
                "version": "1.0",
                "year": 2024,
                "contributor": "Annotation Converter",
                "date_created": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            },
            "licenses": [
                {
                    "id": 1,
                    "name": "Unknown",
                    "url": ""
                }
            ],
            "categories": self.coco_categories,
            "images": [],
            "annotations": []
        }
        
        annotation_id = 1
        image_id_map = {}
        
        # å¤„ç†æ¯å¼ å›¾åƒ
        print("å¼€å§‹è½¬æ¢æ ‡æ³¨...")
        
        for img_idx, file_name in enumerate(file_names):
            # è®¡ç®—åœ¨å“ªä¸ªæ‰¹æ¬¡å’Œæ‰¹æ¬¡å†…ä½ç½®
            batch_idx = img_idx // statistics['batch_size']
            in_batch_idx = img_idx % statistics['batch_size']
            
            if batch_idx >= len(batch_images):
                break
            
            # è·å–å›¾åƒä¿¡æ¯ - ä½¿ç”¨å›ºå®šçš„320x320å°ºå¯¸
            image_info = self._get_original_image_info(file_name)
            image_id = image_info["id"]
            image_id_map[img_idx] = image_id
            
            # ä½¿ç”¨å›ºå®šçš„320x320å°ºå¯¸ï¼Œå› ä¸ºæ‰€æœ‰æ ‡æ³¨éƒ½æ˜¯åŸºäºè¿™ä¸ªå°ºå¯¸çš„
            target_height = 320
            target_width = 320
            
            coco_data["images"].append(image_info)
            
            # è·å–å½“å‰å›¾åƒçš„æ ‡æ³¨
            current_masks = batch_masks[batch_idx][in_batch_idx]  # [H, W, max_instances]
            current_boxes = batch_gt_boxes[batch_idx][in_batch_idx]  # [max_instances, 4]
            current_labels = batch_labels[batch_idx][in_batch_idx]  # [max_instances]
            
            # å¤„ç†æ¯ä¸ªå®ä¾‹
            for inst_idx in range(len(current_labels)):
                label = current_labels[inst_idx]
                
                # è·³è¿‡èƒŒæ™¯ç±»å’Œå¡«å……
                if label <= 0:
                    continue
                
                bbox = current_boxes[inst_idx]
                mask = current_masks[:, :, inst_idx]
                
                # æ£€æŸ¥è¾¹ç•Œæ¡†æœ‰æ•ˆæ€§
                ymin, xmin, ymax, xmax = bbox
                if ymax <= ymin or xmax <= xmin:
                    continue
                
                # å¦‚æœä½¿ç”¨mini maskï¼Œéœ€è¦è§£ç åˆ°320x320å°ºå¯¸
                if statistics['use_mini_mask']:
                    # ä½¿ç”¨å›ºå®šçš„320x320å°ºå¯¸
                    full_mask = self._decode_mini_mask(mask, bbox, 
                                                     (target_height, target_width))
                else:
                    # å¦‚æœä¸æ˜¯mini maskï¼Œéœ€è¦è°ƒæ•´åˆ°320x320å°ºå¯¸
                    if mask.shape != (target_height, target_width):
                        # è°ƒæ•´maskå°ºå¯¸åˆ°320x320
                        mask_resized = cv2.resize(mask.astype(np.float32), 
                                                (target_width, target_height), 
                                                interpolation=cv2.INTER_NEAREST)
                        full_mask = (mask_resized >= 0.5).astype(np.uint8)
                    else:
                        full_mask = mask
                
                # æ£€æŸ¥maskæ˜¯å¦æœ‰æ•ˆ
                if np.sum(full_mask) == 0:
                    continue
                
                # è½¬æ¢ä¸ºRLEæ ¼å¼
                rle = self._mask_to_rle(full_mask)
                
                # è®¡ç®—é¢ç§¯
                area = float(np.sum(full_mask))
                
                # è½¬æ¢è¾¹ç•Œæ¡†æ ¼å¼ [ymin, xmin, ymax, xmax] -> [xmin, ymin, width, height]
                coco_bbox = [float(xmin), float(ymin), float(xmax - xmin), float(ymax - ymin)]
                
                # åˆ›å»ºæ ‡æ³¨
                annotation = {
                    "id": annotation_id,
                    "image_id": image_id,
                    "category_id": int(label),
                    "bbox": coco_bbox,
                    "area": area,
                    "segmentation": rle,
                    "iscrowd": 0
                }
                
                coco_data["annotations"].append(annotation)
                annotation_id += 1
            
            if (img_idx + 1) % 100 == 0:
                print(f"  å·²å¤„ç† {img_idx + 1}/{len(file_names)} å¼ å›¾åƒ")
        
        # å¤åˆ¶å›¾åƒæ–‡ä»¶
        self._copy_images_to_output(file_names, split)
        
        # ä¿å­˜COCOæ ¼å¼æ ‡æ³¨
        output_file = os.path.join(self.output_dir, "annotations", f"instances_{split}2012.json")
        with open(output_file, 'w') as f:
            json.dump(coco_data, f, indent=2)
        
        print(f"\nâœ… {split} æ•°æ®è½¬æ¢å®Œæˆ!")
        print(f"  è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"  å›¾åƒæ•°é‡: {len(coco_data['images'])}")
        print(f"  æ ‡æ³¨æ•°é‡: {len(coco_data['annotations'])}")
        print(f"  ç±»åˆ«æ•°é‡: {len(coco_data['categories'])}")
        
        return output_file
    
    def convert_all(self):
        """è½¬æ¢æ‰€æœ‰æ•°æ®"""
        print("=" * 60)
        print("å¼€å§‹è½¬æ¢æ‰€æœ‰æ ‡æ³¨æ•°æ®ä¸ºCOCOæ ¼å¼")
        print("=" * 60)
        
        results = {}
        
        # è½¬æ¢è®­ç»ƒé›†
        try:
            train_file = self.convert_split('train')
            results['train'] = train_file
        except Exception as e:
            print(f"âŒ è®­ç»ƒé›†è½¬æ¢å¤±è´¥: {e}")
            results['train'] = None
        
        # è½¬æ¢éªŒè¯é›†
        try:
            val_file = self.convert_split('val')
            results['val'] = val_file
        except Exception as e:
            print(f"âŒ éªŒè¯é›†è½¬æ¢å¤±è´¥: {e}")
            results['val'] = None
        
        # ç”Ÿæˆæ•°æ®é›†é…ç½®ä¿¡æ¯
        self._generate_dataset_info()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ è½¬æ¢å®Œæˆ!")
        print("=" * 60)
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print("æ–‡ä»¶ç»“æ„:")
        print("  annotations/")
        print("    â”œâ”€â”€ instances_train2012.json")
        print("    â””â”€â”€ instances_val2012.json")
        print("  images/")
        print("    â”œâ”€â”€ 2007_000027.jpg")
        print("    â””â”€â”€ ...")
        
        return results
    
    def _generate_dataset_info(self):
        """ç”Ÿæˆæ•°æ®é›†é…ç½®ä¿¡æ¯"""
        dataset_info = {
            "dataset_name": "VOC2012_from_pickle",
            "description": "VOC2012 dataset converted from pickle format annotations",
            "classes": self.classes[1:],  # ä¸åŒ…å«èƒŒæ™¯ç±»
            "num_classes": len(self.classes) - 1,
            "data_root": self.output_dir,
            "ann_file": {
                "train": "annotations/instances_train2012.json",
                "val": "annotations/instances_val2012.json"
            },
            "img_prefix": "images/",
            "usage": {
                "mmdetection_config": {
                    "data_root": self.output_dir,
                    "train_ann_file": "annotations/instances_train2012.json",
                    "train_img_prefix": "images/",
                    "val_ann_file": "annotations/instances_val2012.json", 
                    "val_img_prefix": "images/",
                    "test_ann_file": "annotations/instances_val2012.json",
                    "test_img_prefix": "images/"
                }
            }
        }
        
        info_file = os.path.join(self.output_dir, "dataset_info.json")
        with open(info_file, 'w') as f:
            json.dump(dataset_info, f, indent=2)
        
        print(f"ğŸ“‹ æ•°æ®é›†ä¿¡æ¯ä¿å­˜åˆ°: {info_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ æ ‡æ³¨æ ¼å¼è½¬æ¢å™¨ - Pickle to COCO")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    annotation_dir = "./mask_rcnn_in_tf2_keras/final_annotations"
    if not os.path.exists(annotation_dir):
        print(f"âŒ æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {annotation_dir}")
        return
    
    train_file = os.path.join(annotation_dir, "annotations_train.pkl")
    val_file = os.path.join(annotation_dir, "annotations_val.pkl")
    
    if not os.path.exists(train_file):
        print(f"âŒ è®­ç»ƒé›†æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {train_file}")
        return
    
    if not os.path.exists(val_file):
        print(f"âŒ éªŒè¯é›†æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {val_file}")
        return
    
    print(f"âœ… æ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶:")
    print(f"  è®­ç»ƒé›†: {train_file}")
    print(f"  éªŒè¯é›†: {val_file}")
    
    try:
        # åˆ›å»ºè½¬æ¢å™¨
        converter = AnnotationToCOCOConverter()
        
        # æ‰§è¡Œè½¬æ¢
        results = converter.convert_all()
        
        if results['train'] and results['val']:
            print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
            print("1. æ›´æ–°MMDetectioné…ç½®æ–‡ä»¶ä»¥ä½¿ç”¨æ–°çš„COCOæ ¼å¼æ•°æ®")
            print("2. è¿è¡Œ: python update_config_for_coco.py")
            print("3. å¼€å§‹è®­ç»ƒ: python train_models.py --model mask_rcnn")
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 